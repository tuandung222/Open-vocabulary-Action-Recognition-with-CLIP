FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime

# Set working directory
WORKDIR /app

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH="/app:${PYTHONPATH}"

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    git \
    curl \
    wget \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements file and install Python dependencies
COPY requirements.txt .

# Install specific training dependencies
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir dvc 'dvc[gdrive]' 'dvc[s3]' && \
    pip install --no-cache-dir mlflow wandb

# Copy project code
COPY . .

# Default command
ENTRYPOINT ["python"]

# Default parameters - can be overridden with Docker run command
CMD ["train.py", "--distributed_mode=none", "--batch_size=64", "--max_epochs=10"]

# Labels for image metadata
LABEL maintainer="tuandunghcmut" \
      version="1.0" \
      description="CLIP-based Human Action Recognition - Training Environment"
